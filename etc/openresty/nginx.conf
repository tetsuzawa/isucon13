pid /home/isucon/etc/openresty/nginx.pid;
worker_processes auto; # コア数と同じ数まで増やすと良いかも

# nginx worker の設定
worker_rlimit_nofile  262000;  # OS全体で扱えるファイル数 / workerプロセス数 = echo $(cat /proc/sys/fs/file-max) / $(grep -c ^processor /proc/cpuinfo) より小さくなるように設定する。 余裕を持ってworker_connectionsの4倍程度あればいい。なぜなら静的ファイル配信でエフェメラルポート用のソケットファイルと実際に返答するコンテンツファイルの2つのファイルディスクリプタが必要になるから。
events {
    worker_connections 65500;  # 大きくするなら worker_rlimit_nofile も大きくする（file descriptor数の制限を緩める)。port数の最大値に合わせている。
    multi_accept on;  # onにすると複数の接続を同時に受け入れるようになる。高トラフィック時にパフォーマンスが向上する可能性がある。CPU使用率が増加するので注意。
    use epoll;  # 高性能なイベント通知メカニズム。デフォルトでepollが使われることが多いが明示的にonにする。
    accept_mutex_delay 100ms;  # accept()時のmutexの確保に失敗した際の待機時間を調整するためのディレクティブ。デフォルトだと500ms。
    accept_mutex off;  # listenディレクティブでreuseportを使う場合はoffにする。reuse_portを使用すると各ワーカープロセスが独自のソケットを持つことで、接続の受け入れの競合やロックが不要になる。デフォルトはoff。
}


http {
    include       /home/isucon/etc/openresty/mime.types;
    default_type  application/octet-stream;

    server_tokens off;  # Nginxのレスポンスヘッダーからバージョン情報を非表示にして通信量を節約。
    sendfile on;  # nginxで静的ファイル配信を行うときに効果を発揮する。 sendfile システムコールを使用することで、ファイルのコンテンツがユーザスペースとカーネルスペースの間でコピーされるのを避けることができる。結果として、ファイルの転送は大幅に高速化される。
    tcp_nopush on;  # TCP_CORKオプションを使用して、効率的なTCPトラフィックを可能にする。レスポンスヘッダとファイルの内容をまとめて送るようになるので送信するパケット数を最小化できる。
    tcp_nodelay on;  # 小さいパケットの遅延を回避
    keepalive_timeout 120;
    client_max_body_size 10m;

    open_file_cache max=200000 inactive=20s;  # nginxには一度オープンしたファイルのディスクリプタやサイズ、更新時刻、i-nodeといった情報をキャッシュする
    open_file_cache_valid 30s;  # この時間が経過すると、キャッシュアイテムは再検証される。
    open_file_cache_min_uses 2;  # よくアクセスされるファイルのみをキャッシュすることで、キャッシュの効率を向上させることができる。
    open_file_cache_errors on;  # エラー結果もキャッシュすることで繰り返し同じエラーが発生するのを防ぐ

    gzip on; # 静的ファイルのリアルタイム圧縮を有効にする。gzip_staticとは競合しない。
    gzip_types text/plain text/css text/javascript application/javascript application/x-javascript application/json; # text/htmlはデフォルトで有効なので記述不要
    gzip_min_length 1k;
    gzip_comp_level 6;
    gzip_static on;  # 事前に gzip 圧縮された静的ファイルの提供が有効になる。リクエストがexample.cssの場合、Nginxはexample.css.gzが存在するかどうかを確認し、存在する場合はそれを返す。存在しない場合は、Nginxはexample.cssをgzip圧縮して返す。
    gzip_vary on;
    gzip_buffers 100 32k;  # 32KB * 100 = 3200KB のgzip用バッファを用意する。
    gzip_http_version 1.1;  # HTTP1.0以下を使用する場合、keepaliveが使えないのでgzip圧縮のオーバヘッドが圧縮のメリットを上回る可能性がある。
    # gzip_proxied any;  # リバースプロキシのレスポンスをgzip圧縮する場合は、anyを指定する。しない場合はoffを指定する。

    proxy_buffer_size 4k;  # アップストリームサーバからの最初のレスポンス部分（通常はヘッダー）をバッファリングするためのバッファのサイズ。
    proxy_buffers 100 32k;  # 32KB * 100 = 3200KB。のアップストリームサーバからのレスポンスボディをバッファリングするためのバッファの数とサイズ。
    proxy_busy_buffers_size 640k;  # バッファがいっぱいになった場合に、アップストリームサーバからのレスポンスを待機させるためのバッファのサイズ。アップストリームからの応答が高速だが、クライアントがデータを遅く受信する場合に有効。

    # Proxy cache 設定。使いどころがあれば。1mでkey8,000個。1gまでcache。
    # proxy_cache_path /var/cache/nginx/cache levels=1:2 keys_zone=zone1:1m max_size=1g inactive=1h;
    # proxy_temp_path  /var/cache/nginx/tmp;

    # オリジンから来るCache-Controlを無視する必要があるなら。。。
    #proxy_ignore_headers Cache-Control;

    # access_log /var/log/nginx/access.log;
    log_format json escape=json '{"time":"$time_local",'
                                '"host":"$remote_addr",'
                                '"forwardedfor":"$http_x_forwarded_for",'
                                '"req":"$request",'
                                '"status":"$status",'
                                '"method":"$request_method",'
                                '"uri":"$request_uri",'
                                '"body_bytes":$body_bytes_sent,'
                                '"referer":"$http_referer",'
                                '"ua":"$http_user_agent",'
                                '"accept_encoding":"$http_accept_encoding",'
                                '"request_time":$request_time,'
                                '"if_none_match":"$http_if_none_match",'
                                '"cache":"$upstream_http_x_cache",'
                                '"upstream_http_cache_status":"$upstream_http_cache_status",'
                                '"upstream_cache_status":"$upstream_cache_status",'
                                '"runtime":"$upstream_http_x_runtime",'
                                '"response_time":"$upstream_response_time",'
                                '"vhost":"$host",'
                                '"request_id":"$request_id",'
                                '"trace_id":"$trace_id"}';

    access_log  /home/isucon/log/nginx/access.log json;
    error_log  /home/isucon/log/nginx/error.log;

    proxy_set_header X-Request-ID $request_id;

    # TLS configuration
    ssl_protocols TLSv1.2;
    ssl_prefer_server_ciphers on;
    ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384';

    # ================================ trace_id ================================
    map $http_cookie $trace_id {
        default $request_id;  # trace_id cookieが存在しない場合、request_idを使用
        "~*trace_id=([^;]+)" $1;  # trace_id cookieが存在する場合、その値を使用
    }

    # https://github.com/thibaultcha/lua-resty-jit-uuid
    init_worker_by_lua_block {
        require "resty.core"
        local uuid = require 'resty.jit-uuid'
        uuid.seed()
    }

    include /home/isucon/etc/openresty/conf.d/*.conf;
}
